{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.2.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain) (0.2.3)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain) (0.2.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain) (0.1.67)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain) (2.7.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (8.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.18.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/codespace/.local/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/codespace/.local/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (2.4)\n",
      "Requirement already satisfied: openai in /usr/local/python/3.10.13/lib/python3.10/site-packages (1.30.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/lib/python3.10/site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from openai) (2.7.2)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/codespace/.local/lib/python3.10/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.18.3)\n",
      "Requirement already satisfied: langchain_experimental in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.0.59)\n",
      "Requirement already satisfied: langchain-community<0.3,>=0.2 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain_experimental) (0.2.1)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain_experimental) (0.2.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/codespace/.local/lib/python3.10/site-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (0.6.6)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (0.2.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (0.1.67)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/codespace/.local/lib/python3.10/site-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (8.3.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2->langchain_experimental) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2->langchain_experimental) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2->langchain_experimental) (2.7.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3,>=0.2->langchain_experimental) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3,>=0.2->langchain_experimental) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3,>=0.2->langchain_experimental) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3,>=0.2->langchain_experimental) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3,>=0.2->langchain_experimental) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3,>=0.2->langchain_experimental) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3,>=0.2->langchain_experimental) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3,>=0.2->langchain_experimental) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/codespace/.local/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2->langchain_experimental) (2.4)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.0->langchain-community<0.3,>=0.2->langchain_experimental) (0.2.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community<0.3,>=0.2->langchain_experimental) (3.10.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langchain_experimental) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langchain_experimental) (2.18.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/codespace/.local/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langchain_experimental) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain-community<0.3,>=0.2->langchain_experimental) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain-community<0.3,>=0.2->langchain_experimental) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests<3,>=2->langchain-community<0.3,>=0.2->langchain_experimental) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain-community<0.3,>=0.2->langchain_experimental) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.3,>=0.2->langchain_experimental) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.3,>=0.2->langchain_experimental) (1.0.0)\n",
      "Requirement already satisfied: tiktoken in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.7.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tiktoken) (2024.5.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/codespace/.local/lib/python3.10/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
      "Requirement already satisfied: faiss-cpu==1.7.4 in /usr/local/python/3.10.13/lib/python3.10/site-packages (1.7.4)\n"
     ]
    }
   ],
   "source": [
    "# Use termcolor to make it easy to colorize the outputs.\n",
    "!pip install termcolor > /dev/null\n",
    "!pip install langchain\n",
    "!pip install openai\n",
    "!pip install langchain_experimental\n",
    "!pip install tiktoken\n",
    "!pip install faiss-cpu==1.7.4\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List\n",
    "import math\n",
    "import faiss\n",
    "import os\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
    "from langchain.vectorstores import FAISS\n",
    "from termcolor import colored\n",
    "from langchain_experimental.generative_agents import (\n",
    "\n",
    "    GenerativeAgent,\n",
    "    GenerativeAgentMemory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"7ff1265c442c42f197110c2d91f13da9\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://mainaoai.openai.azure.com/\"\n",
    "os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2024-02-01\"\n",
    "os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"] = \"main4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_NAME = \"Hikaru\"\n",
    "\n",
    "\n",
    "LLM = AzureChatOpenAI(\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevance_score_fn(score: float) -> float:\n",
    "    \"\"\"Return a similarity score on a scale [0, 1].\"\"\"\n",
    "    # This will differ depending on a few things:\n",
    "    # - the distance / similarity metric used by the VectorStore\n",
    "    # - the scale of your embeddings (OpenAI's are unit norm. Many others are not!)\n",
    "    # This function converts the euclidean norm of normalized embeddings\n",
    "    # (0 is most similar, sqrt(2) most dissimilar)\n",
    "    # to a similarity function (0 to 1)\n",
    "    return 1.0 - score / math.sqrt(2)\n",
    "\n",
    "\n",
    "def create_new_memory_retriever():\n",
    "    \"\"\"Create a new vector store retriever unique to the agent.\"\"\"\n",
    "    # Define your embedding model\n",
    "    embeddings_model = AzureOpenAIEmbeddings()\n",
    "    # Initialize the vectorstore as empty\n",
    "    embedding_size = 1536\n",
    "    index = faiss.IndexFlatL2(embedding_size)\n",
    "    vectorstore = FAISS(\n",
    "        embeddings_model.embed_query,\n",
    "        index,\n",
    "        InMemoryDocstore({}),\n",
    "        {},\n",
    "        relevance_score_fn=relevance_score_fn,\n",
    "    )\n",
    "    return TimeWeightedVectorStoreRetriever(\n",
    "        vectorstore=vectorstore, other_score_keys=[\"importance\"], k=15\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexis_memory = GenerativeAgentMemory(\n",
    "    llm=LLM,\n",
    "    memory_retriever=create_new_memory_retriever(),\n",
    "    verbose=False,\n",
    "    reflection_threshold=8,  # we will give this a relatively low number to show how reflection works\n",
    ")\n",
    "\n",
    "# Defining the Generative Agent: Alexis\n",
    "alexis = GenerativeAgent(\n",
    "    name=\"Alexis\",\n",
    "    age=30,\n",
    "    traits=\"curious, creative writer, world traveler\",  # Persistent traits of Alexis\n",
    "    status=\"exploring the intersection of technology and storytelling\",  # Current status of Alexis\n",
    "    memory_retriever=create_new_memory_retriever(),\n",
    "    llm=LLM,\n",
    "    memory=alexis_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/langchain_generative_ai_agent/implementing_agents.ipynb セル 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bspecial-couscous-q5qrx7j4pp424jrx/workspaces/langchain_generative_ai_agent/implementing_agents.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m alexis_observations \u001b[39m=\u001b[39m [\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bspecial-couscous-q5qrx7j4pp424jrx/workspaces/langchain_generative_ai_agent/implementing_agents.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mAlexis recalls her morning walk in the park\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bspecial-couscous-q5qrx7j4pp424jrx/workspaces/langchain_generative_ai_agent/implementing_agents.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mAlexis feels excited about the new book she started reading\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bspecial-couscous-q5qrx7j4pp424jrx/workspaces/langchain_generative_ai_agent/implementing_agents.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mAlexis contemplates her goals for the month.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bspecial-couscous-q5qrx7j4pp424jrx/workspaces/langchain_generative_ai_agent/implementing_agents.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m ]\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bspecial-couscous-q5qrx7j4pp424jrx/workspaces/langchain_generative_ai_agent/implementing_agents.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m observation \u001b[39min\u001b[39;00m alexis_observations:\n\u001b[0;32m---> <a href='vscode-notebook-cell://codespaces%2Bspecial-couscous-q5qrx7j4pp424jrx/workspaces/langchain_generative_ai_agent/implementing_agents.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     alexis\u001b[39m.\u001b[39;49mmemory\u001b[39m.\u001b[39;49madd_memory(observation)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bspecial-couscous-q5qrx7j4pp424jrx/workspaces/langchain_generative_ai_agent/implementing_agents.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# We will see how this summary updates after more observations to create a more rich description.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bspecial-couscous-q5qrx7j4pp424jrx/workspaces/langchain_generative_ai_agent/implementing_agents.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(alexis\u001b[39m.\u001b[39mget_summary(force_refresh\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain_experimental/generative_agents/memory.py:204\u001b[0m, in \u001b[0;36mGenerativeAgentMemory.add_memory\u001b[0;34m(self, memory_content, now)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maggregate_importance \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m importance_score\n\u001b[1;32m    201\u001b[0m document \u001b[39m=\u001b[39m Document(\n\u001b[1;32m    202\u001b[0m     page_content\u001b[39m=\u001b[39mmemory_content, metadata\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mimportance\u001b[39m\u001b[39m\"\u001b[39m: importance_score}\n\u001b[1;32m    203\u001b[0m )\n\u001b[0;32m--> 204\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmemory_retriever\u001b[39m.\u001b[39;49madd_documents([document], current_time\u001b[39m=\u001b[39;49mnow)\n\u001b[1;32m    206\u001b[0m \u001b[39m# After an agent has processed a certain amount of memories (as measured by\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39m# aggregate importance), it is time to reflect on recent events to add\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[39m# more synthesized memories to the agent's memory stream.\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    210\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreflection_threshold \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maggregate_importance \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreflection_threshold\n\u001b[1;32m    212\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreflecting\n\u001b[1;32m    213\u001b[0m ):\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain/retrievers/time_weighted_retriever.py:165\u001b[0m, in \u001b[0;36mTimeWeightedVectorStoreRetriever.add_documents\u001b[0;34m(self, documents, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m     doc\u001b[39m.\u001b[39mmetadata[\u001b[39m\"\u001b[39m\u001b[39mbuffer_idx\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory_stream) \u001b[39m+\u001b[39m i\n\u001b[1;32m    164\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory_stream\u001b[39m.\u001b[39mextend(dup_docs)\n\u001b[0;32m--> 165\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvectorstore\u001b[39m.\u001b[39;49madd_documents(dup_docs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain_core/vectorstores.py:138\u001b[0m, in \u001b[0;36mVectorStore.add_documents\u001b[0;34m(self, documents, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m texts \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mpage_content \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    137\u001b[0m metadatas \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mmetadata \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[0;32m--> 138\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_texts(texts, metadatas, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain_community/vectorstores/faiss.py:227\u001b[0m, in \u001b[0;36mFAISS.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Run more texts through the embeddings and add to the vectorstore.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \n\u001b[1;32m    218\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[39m    List of ids from adding the texts into the vectorstore.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    226\u001b[0m texts \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(texts)\n\u001b[0;32m--> 227\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embed_documents(texts)\n\u001b[1;32m    228\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__add(texts, embeddings, metadatas\u001b[39m=\u001b[39mmetadatas, ids\u001b[39m=\u001b[39mids)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain_community/vectorstores/faiss.py:138\u001b[0m, in \u001b[0;36mFAISS._embed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_function\u001b[39m.\u001b[39membed_documents(texts)\n\u001b[1;32m    137\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 138\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_function(text) \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m texts]\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain_community/vectorstores/faiss.py:138\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_function\u001b[39m.\u001b[39membed_documents(texts)\n\u001b[1;32m    137\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 138\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding_function(text) \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m texts]\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain_community/embeddings/openai.py:697\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39membed_query\u001b[39m(\u001b[39mself\u001b[39m, text: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mfloat\u001b[39m]:\n\u001b[1;32m    689\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call out to OpenAI's embedding endpoint for embedding query text.\u001b[39;00m\n\u001b[1;32m    690\u001b[0m \n\u001b[1;32m    691\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[39m        Embedding for the text.\u001b[39;00m\n\u001b[1;32m    696\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 697\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_documents([text])[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain_community/embeddings/openai.py:668\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[0;34m(self, texts, chunk_size)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[39m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[1;32m    666\u001b[0m \u001b[39m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[1;32m    667\u001b[0m engine \u001b[39m=\u001b[39m cast(\u001b[39mstr\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeployment)\n\u001b[0;32m--> 668\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_len_safe_embeddings(texts, engine\u001b[39m=\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain_community/embeddings/openai.py:494\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[1;32m    492\u001b[0m batched_embeddings: List[List[\u001b[39mfloat\u001b[39m]] \u001b[39m=\u001b[39m []\n\u001b[1;32m    493\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m _iter:\n\u001b[0;32m--> 494\u001b[0m     response \u001b[39m=\u001b[39m embed_with_retry(\n\u001b[1;32m    495\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    496\u001b[0m         \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mtokens[i : i \u001b[39m+\u001b[39;49m _chunk_size],\n\u001b[1;32m    497\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_invocation_params,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    499\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    500\u001b[0m         response \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mdict()\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain_community/embeddings/openai.py:116\u001b[0m, in \u001b[0;36membed_with_retry\u001b[0;34m(embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Use tenacity to retry the embedding call.\"\"\"\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m is_openai_v1():\n\u001b[0;32m--> 116\u001b[0m     \u001b[39mreturn\u001b[39;00m embeddings\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    117\u001b[0m retry_decorator \u001b[39m=\u001b[39m _create_retry_decorator(embeddings)\n\u001b[1;32m    119\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_embed_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/openai/resources/embeddings.py:114\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    108\u001b[0m         embedding\u001b[39m.\u001b[39membedding \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfrombuffer(  \u001b[39m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[1;32m    109\u001b[0m             base64\u001b[39m.\u001b[39mb64decode(data), dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m         )\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m    112\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\n\u001b[0;32m--> 114\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[1;32m    115\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m/embeddings\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    116\u001b[0m     body\u001b[39m=\u001b[39;49mmaybe_transform(params, embedding_create_params\u001b[39m.\u001b[39;49mEmbeddingCreateParams),\n\u001b[1;32m    117\u001b[0m     options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[1;32m    118\u001b[0m         extra_headers\u001b[39m=\u001b[39;49mextra_headers,\n\u001b[1;32m    119\u001b[0m         extra_query\u001b[39m=\u001b[39;49mextra_query,\n\u001b[1;32m    120\u001b[0m         extra_body\u001b[39m=\u001b[39;49mextra_body,\n\u001b[1;32m    121\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    122\u001b[0m         post_parser\u001b[39m=\u001b[39;49mparser,\n\u001b[1;32m    123\u001b[0m     ),\n\u001b[1;32m    124\u001b[0m     cast_to\u001b[39m=\u001b[39;49mCreateEmbeddingResponse,\n\u001b[1;32m    125\u001b[0m )\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/openai/_base_client.py:1240\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[1;32m   1227\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1228\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1235\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1236\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m   1237\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[1;32m   1238\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[1;32m   1239\u001b[0m     )\n\u001b[0;32m-> 1240\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/openai/_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    913\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    920\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m--> 921\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m    922\u001b[0m         cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[1;32m    923\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    924\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    925\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m    926\u001b[0m         remaining_retries\u001b[39m=\u001b[39;49mremaining_retries,\n\u001b[1;32m    927\u001b[0m     )\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/openai/_base_client.py:1020\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1017\u001b[0m         err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mread()\n\u001b[1;32m   1019\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mRe-raising status error\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1020\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_status_error_from_response(err\u001b[39m.\u001b[39mresponse) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_response(\n\u001b[1;32m   1023\u001b[0m     cast_to\u001b[39m=\u001b[39mcast_to,\n\u001b[1;32m   1024\u001b[0m     options\u001b[39m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     stream_cls\u001b[39m=\u001b[39mstream_cls,\n\u001b[1;32m   1028\u001b[0m )\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}"
     ]
    }
   ],
   "source": [
    "# We can add memories directly to the memory object\n",
    "\n",
    "alexis_observations = [\n",
    "    \"Alexis recalls her morning walk in the park\",\n",
    "    \"Alexis feels excited about the new book she started reading\",\n",
    "    \"Alexis remembers her conversation with a close friend\",\n",
    "    \"Alexis thinks about the painting she saw at the art gallery\",\n",
    "    \"Alexis is planning to learn a new recipe for dinner\",\n",
    "    \"Alexis is looking forward to her weekend trip\",\n",
    "    \"Alexis contemplates her goals for the month.\"\n",
    "]\n",
    "\n",
    "for observation in alexis_observations:\n",
    "    alexis.memory.add_memory(observation)\n",
    "\n",
    "\n",
    "\n",
    "# We will see how this summary updates after more observations to create a more rich description.\n",
    "print(alexis.get_summary(force_refresh=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
